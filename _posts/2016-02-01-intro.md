---
title: "DLMHS 2018"
bg: white
color: black
style: left
fa-icon: list-ul
layout: default
icon-title: true
---
  
<div style="text-align:center;">
  <span class="fa-stack subtlecircle" style="font-size:64px; background:rgba(0,128,0,0.1)">
    <i class="fa fa-circle fa-stack-2x text-white"></i>
    <i class="fa fa-server fa-stack-1x text-green"></i>
  </span>
</div>

## June 12, 2018, Beijing, China.

<div style="text-align:center;">
  <a href="http://ics2018.ict.ac.cn/"><img width="640px" src="img/ICS-18-logo-1.png"/></a>
  &nbsp;  &nbsp;  &nbsp;  &nbsp;
</div>

#### Held in conjunction with the 32nd ACM International Conference on Supercomputing([ACM ICS-2018](http://ics2018.ict.ac.cn/)), June 12-15, 2018, Beijing, China.

<div style="text-align:center;">
  <p>
  <font style="color:red;font-size:18pt;font-face:bold;">
  Submission deadline for abstract is May 1st, 2018 (AOE)
  </font>
  </p>
</div>

### Overview
The last decade has seen blooming emergence in deep learning. With ever-increased problem size to resolve and data size to process, deep learning becomes extremely computation demanding. As a result, migrating deep learning algorithms and applications on modern supercomputers, especially heterogeneous supercomputers that incorporate special accelerators such as GPUs, Xeon-Phi, FPGA, TPU, ASIC, etc. becomes a trend. 


<div style="text-align:center;">
  <p>
    <a href="dlmhs-cfp.txt">
      <i class="fa fa-file-text-o">&nbsp;<b>Download the DLMHS 18 CFP </b></i>
    </a>
  </p>
</div>

## Topics

This workshop will emphasize novel, disruptive research ideas over incremental 
advances. We will solicit papers on topics including, but not limited to, the 
following areas:

In this workshop, we invite novel and recent works including, but not limited to, the following topics:
* Scalable deep learning algorithms and application 
* Heterogeneous programming models and interfaces for deep learning
* Special compilation techniques for deep-learning on heterogeneous supercomputers
* Practical experience and evaluations on accelerator interconnects (GPU, FPGA, Xeon-Phi)
* Memory and Cache optimization techniques for deep learning applications
* Power reduction techniques for deep-learning applications
* Performance Modeling for deep learning applications on supercomputers
* Potential Opportunities for HPC from deep learning type of applications, e.g., gradient-descent enabled approximate computing
* Potential Challenges for scaling current deep learning algorithms on supercomputers (e.g., communication bottlenecks, load balancing, etc)


## Submissions

As a brand new workshop, we decide to make it discussion oriented this year. We invite 2-page double-column submission on novel and recent published works. We also welcome unfinished novel ideas. Please follow the ACM proceeding sigconf template ([https://www.acm.org/publications/proceedings-template](https://www.acm.org/publications/proceedings-template)) using 10-point font for submission. Kindly note that the submission will not appear in proceedings so it can be further developed and submitted to a formal conference or journals. Finished or published works will be given 25 minutes to fully describe their contributions while unfinished work and novel ideas will be given 10 minutes to motivate the audience. 

Submission will be accepted through the EasyChair System through this link: ([https://easychair.org/conferences/?conf=dlmhs18](https://easychair.org/conferences/?conf=dlmhs18))

## Important Dates

* Abstract (2 pages max):  
* Deadline: May. 1st, 2018 (AOE)
* Author notification: May 13th, 2018 (AOE)

All dates are Anywhere on Earth (AOE)

## General Chairs

* Ang Li, Pacific Northwest National Laboratory, USA
* Jidong Zhai, Tsinghua University, China

## Program Committee

* Shuaiwen Leon Song, Pacific Northwest National Laboratory, USA
* Xu Liu, College of William and Mary, USA
* Weifeng Liu, Norwegian University of Science and Technology, Norway
* Guoyang Chen, Qualcomm, USA
* Jiajia Li, Georgia Tech University, USA
* Dingwen Tao, Brookhaven National Laboratory, USA
* Shuai Che, AMD Research, USA 
* Qiang Guan, Kent State University, USA
* Yun Liang, Peking University, China
* Akash Kumar, Dresden University of Technology, Germany
* Wenfeng Zhao, University of Minnesota, USA
* Biao Sun, Tianjin University, China
* Joseph Manzano, Pacific Northwest National Laboratory, USA




## Workshop Program

<table style="width:90%;border:1px;margin-left:auto;margin-right:auto;margin-top:1em;margin-bottom:1em">
<tr><td style="width:20%;vertical-align:top;text-align:center;background-color:#D5F5E3;"><b>09:00 AM to 09:15 AM</b></td><td style="width:80%;background-color:#F6DDCC;">Welcome and Workshop Introduction </td></tr>
<tr><td style="width:20%;vertical-align:top;text-align:center;background-color:#D5F5E3;"><b>09:15 AM to 10:00 AM</b></td><td style="width:80%;background-color:#F6DDCC;">Keynote: Hank Hoffmann, University of Chicago </td></tr>
<tr><td style="width:20%;vertical-align:top;text-align:center;background-color:#D5F5E3;"><b>10:00 AM to 10:30 AM</b></td><td style="width:80%;background-color:#F6DDCC;">Break </td></tr>
<tr><td style="width:20%;vertical-align:top;text-align:center;background-color:#FCF3CF;"><b>10:30 AM to 12:00 PM</b></td><td style="width:80%;background-color:#F6DDCC;">
  <p><font style="font-face:bold;"><b>Non-Intrusive Migration of MPI Processes in OS-bypass Networks</b></font> Simon Pickartz (RWTH Aachen University), Carsten Clauss (ParTec Cluster Competence Center GmbH), Stefan Lankes (RWTH Aachen University), Stephan Krempel (ParTec Cluster Competence Center GmbH), Thomas Moschny (ParTec Cluster Competence Center GmbH), Antonello Monti (RWTH Aachen University) </p>
  <p><font style="font-face:bold;"><b>Photon: Remote Memory Access Middleware for High-Performance Runtime Systems</b></font> Ezra Kissel, Martin Swany (Indiana University) </p>
  <p><font style="font-face:bold;"><b>Asynchronous Runtimes in Action: An Introspective Framework for a Next Gen Runtime</b></font> Joshua Suetterlein (University of Delaware), Joshua Landwehr (University of Delaware), Andres Marquez (Pacific Northwest National Lab), Joseph Manzano (Pacific Northwest National Lab), Guang R Gao (University of Delaware)</p>
</td></tr>
<tr><td style="width:20%;vertical-align:top;text-align:center;background-color:#D5F5E3;"><b>12:00 PM to 01:15 PM</b></td><td style="width:80%;background-color:#F6DDCC;">Lunch </td></tr>
<tr><td style="width:20%;vertical-align:top;text-align:center;background-color:#FCF3CF;"><b>01:15 PM to 02:45 PM</b></td><td style="width:80%;background-color:#F6DDCC;">
  <p>Session 2 -- Chair: Todd Gamblin, Lawrence Livermore National Lab</p>
  <p><font style="font-face:bold;"><b>OWBP: Flash-Aware Offline Write Buffer Policy</b></font> Alireza Haghdoost, David H.C. Du (University of Minnesota)</p>
  <p><font style="font-face:bold;"><b>Topology-Aware Rank Reordering for MPI Collectives</b></font> Seyed Hessamedin Mirsadeghi, Ahmad Afsahi (Queenâ€™s Univeristy)</p>
  <p><font style="font-face:bold;"><b>GPUShare: Fair-sharing Middleware for GPU Clouds</b></font> Anshuman Goswami, Jeffrey Young, Karsten Schwan, Naila Farooqui, Ada Gavrilovska, Matthew Wolf, Greg Eisenhauer (Georgia Tech)</p>
</td></tr>
<tr><td style="width:20%;vertical-align:top;text-align:center;background-color:#D5F5E3;"><b>02:45 PM to 03:15 PM</b></td><td style="width:80%;background-color:#F6DDCC;">Break </td></tr>
<tr><td style="width:20%;vertical-align:top;text-align:center;background-color:#FCF3CF;"><b>03:15 PM to 04:45 PM</b></td><td style="width:80%;background-color:#F6DDCC;">
  <p>Session 3 -- Chair: Joseph Manzano, Pacific Northwest National Lab</p>  <p><font style="font-face:bold;"><b>Performance Characterization of Hypervisor- and Container-based Virtualization for HPC on SR-IOV Enabled InfiniBand Clusters</b></font> Jie Zhang, Xiaoyi Lu, Dhabaleswar K. (DK) Panda (The Ohio State University)</p>
  <p><font style="font-face:bold;"><b>Macaca: A Scalable and Energy-Efficient Platform for Coupling Cloud Computing with Distributed Embedded Computing</b></font> Heng Zhang, Chunliang Hao, Yanjun Wu, Mingshu Li (Institute of Software, Chinese Academy of Science)</p>
  <p><font style="font-face:bold;"><b>Benchmarking Streaming Computation Engines: Storm, Flink and Spark Streaming</b></font> Sanket Chintapalli, Derek Dagit, Bobby Evans, Reza Farivar, Thomas Graves, Mark Holderbaugh, Zhuo Liu, Kyle Nusbaum, Kishorkumar Patil, Boyang Jerry Peng, Paul Poulosky (Yahoo! Inc)</p>
</td></tr>
<tr><td style="width:20%;vertical-align:top;text-align:center;background-color:#D5F5E3;"><b>04:45 PM to 04:55 PM</b></td><td style="width:80%;background-color:#F6DDCC;">Workshop Closing Comments </td></tr>
</table>

## Keynote

### Title

What is the Big Deal About Approximate Computing?

### Speaker

Hank Hoffmann, University of Chicago

### Abstract

Approximate computing has recently received a great deal of attention from a range of researchers including circuit designers, hardware architects, and programming language designers.  This talk discusses some of the recent trends in approximate computing and then argues that really approximation is something that application developers have been doing all along.  So, perhaps the biggest insight in the current trend in approximation is that by exposing the things applications developers approximate to the rest of the computer system, there is the opportunity to do even more.  We then investigate one of those things that is possible when the computer system can coordinate with an approximate application.

Specifically, we discuss JouleGuard: a framework that coordinates approximate applications with system resource usage to meet user-defined energy goals with  control theoretic formal guarantees. We show results of using JouleGuard  on three different platforms (a mobile, tablet, and server) with eight different approximate applications created from two different frameworks. We find that JouleGuard respects energy budgets, provides near optimal accuracy, adapts to phases in application workload, and provides better outcomes than application approximation or system resource adaptation alone. JouleGuard is general with respect to the applications and systems it controls, making it a suitable runtime for a number of approximate computing frameworks.

